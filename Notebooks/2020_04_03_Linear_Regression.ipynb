{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Analysis: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd # to read CSV\n",
    "from sklearn import linear_model, model_selection # for multivariable linear regression\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import gc\n",
    "for obj in gc.get_objects():   # Browse through ALL objects\n",
    "    if isinstance(obj, h5py.File):   # Just HDF5 files\n",
    "        try:\n",
    "            obj.close()\n",
    "        except:\n",
    "            pass # Was already closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] Input LCs and get LC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2682 files from /blender/data/hblim/exoplanet/ML_Exoplanet_Project/Data/TICS/sector-21/preprocessed\n",
      "Loaded 1064 files from /blender/data/hblim/exoplanet/ML_Exoplanet_Project/Data/TICS/sector-20/preprocessed\n",
      "Loaded  781 files from /blender/data/hblim/exoplanet/ML_Exoplanet_Project/Data/TICS/sector-19/preprocessed\n",
      "Loaded  694 files from /blender/data/hblim/exoplanet/ML_Exoplanet_Project/Data/TICS/sector-18/preprocessed\n",
      "Loaded  563 files from /blender/data/hblim/exoplanet/ML_Exoplanet_Project/Data/TICS/sector-17/preprocessed\n",
      "Loaded  757 files from /blender/data/hblim/exoplanet/ML_Exoplanet_Project/Data/TICS/sector-14/preprocessed\n",
      "Loaded 4119 files from /blender/data/hblim/exoplanet/ML_Exoplanet_Project/Data/TICS/sector-13/preprocessed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-371d7fa5c0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Close h5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mlcfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mnsector\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blender/data/hblim/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0m_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlocal_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Global folder paths\n",
    "datapath  = \"/blender/data/hblim/exoplanet/ML_Exoplanet_Project/Data/TICS/\"\n",
    "\n",
    "# Manually include which sectors names to scan\n",
    "# sectors = [\"sector-{}\".format(i) for i in \\\n",
    "#            [1,2,3,4,5,6,7,8,9,10,11,12,13,14,17,18,19,20,21]]\n",
    "sectors = [\"sector-{}\".format(i) for i in \\\n",
    "           [12,13,14,17,18,19,20,21]]\n",
    "\n",
    "# Construct lcpaths from sector names: /TICS/sector/preprocessed/*.h5\n",
    "lcsectorpaths = []\n",
    "for sector in sectors:\n",
    "    lcpath = os.path.join(datapath,sector,\"preprocessed\")\n",
    "    assert os.path.exists(lcpath), \"{} data does not exist\".format(sector)\n",
    "    lcsectorpaths.append(lcpath)\n",
    "\n",
    "# Import all .h5 files and names from each sector\n",
    "lcfiles = []\n",
    "lcnames = []\n",
    "\n",
    "# Loop through all files in sector folder\n",
    "# Get data\n",
    "#[0] astronet score\n",
    "#[1] depth best ap (global)\n",
    "#[2] depth best ap - 1\n",
    "#[3] depth best ap + 1 or best ap\n",
    "#[4] SNR\n",
    "#[5] depth best ap (local)\n",
    "#[6] depth best ap - 1\n",
    "#[7] depth best ap + 1 or best ap\n",
    "#[8] SNR\n",
    "data = np.zeros((0,7))\n",
    "\n",
    "# For duplicate lcs in multiple sectors, only upload latest\n",
    "nomit    = 0\n",
    "for i in range(len(lcsectorpaths)-1,-1,-1):\n",
    "    lcsectorpath= lcsectorpaths[i]\n",
    "    \n",
    "    nsector  = 0\n",
    "    for lcfile in os.listdir(lcsectorpath):\n",
    "\n",
    "        # Before opening, check if LC file has .h5 extension and not in more recent sector\n",
    "        if (lcfile.split(\".\")[-1] == \"h5\") and (lcfile not in lcnames):\n",
    "            # Open h5 file\n",
    "            lcfiles.append(h5py.File(os.path.join(lcsectorpath,lcfile),'r'))\n",
    "            \n",
    "            # Store name\n",
    "            lcnames.append(lcfile)\n",
    "            \n",
    "            # Read in Data\n",
    "            datat = np.zeros((1,7))\n",
    "            datat[0][0] = float(lcfiles[-1][\"AstroNetScore\"][0])  \n",
    "            gdepths = []\n",
    "            ldepths = []\n",
    "            globalstd = 0\n",
    "            for ap in range(len(lcfiles[-1][\"GlobalView\"].keys())):\n",
    "                gview = lcfiles[-1][\"GlobalView\"][\"Aperture_%.3d\" % (ap)]\n",
    "                lview = lcfiles[-1][\"LocalView\"][\"Aperture_%.3d\" % (ap)]\n",
    "                gdepths.append(np.amin(gview))\n",
    "                ldepths.append(np.amin(lview))        \n",
    "                # Mean noise level for SNR\n",
    "                globalstd += np.std(gview)\n",
    "            globalstd /= 5\n",
    "            datat[0][1] = np.mean(gdepths)\n",
    "            datat[0][2] = np.std(gdepths)\n",
    "            datat[0][3] = np.mean(gdepths) / globalstd\n",
    "            datat[0][4] = np.mean(ldepths)\n",
    "            datat[0][5] = np.std(ldepths)\n",
    "            datat[0][6] = np.mean(ldepths) / globalstd\n",
    "            data = np.append(data,datat,axis=0)\n",
    "            \n",
    "            # Close h5 file\n",
    "            lcfiles[-1].close()\n",
    "            nsector += 1\n",
    "        else:\n",
    "            nomit += 1\n",
    "            \n",
    "    print(\"Loaded {:4d} files from {}\".format(nsector,lcsectorpath))\n",
    "\n",
    "nfiles = len(lcfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1.2] Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 213 planets and 21533 non-planets\n"
     ]
    }
   ],
   "source": [
    "labels = np.zeros(len(lcnames),dtype='i8')\n",
    "\n",
    "labels_tsv = np.genfromtxt(os.path.join(datapath,\"labels.tsv\"), \\\n",
    "                       delimiter=\"\\t\",skip_header=3,usecols=(0,11),dtype=\"i8,S5\",names=[\"id\",\"label\"])\n",
    "\n",
    "for i in range(len(lcnames)):\n",
    "    if int(lcnames[i][:-3]) in list(labels_tsv['id']):\n",
    "        labels[i] = 1\n",
    "        \n",
    "print(\"Found {} planets and {} non-planets\".format(np.sum(labels == 1),np.sum(labels == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] Linear Regression \n",
    "K Fold cross-validation with 5 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "y = labels\n",
    "kfold = model_selection.KFold(n_splits = 5,shuffle=True)\n",
    "\n",
    "kfold_loss = [] # RMSE per case\n",
    "kfold_predict = [] # predict class\n",
    "kfold_classifies = [] # (n_right, n_right and planet, n_falsepositive, n_falsenegative)\n",
    "\n",
    "kfold_coefs = []\n",
    "for train_index, test_index in kfold.split(data):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # do multilinear regression\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(X_train,y_train)\n",
    "    kfold_coefs.append(reg.coef_)\n",
    "    \n",
    "    # loss\n",
    "    kfold_loss.append(np.linalg.norm(y_test - np.dot(X_test,np.array([reg.coef_]).T)) / len(y_test))\n",
    "    \n",
    "    # prediction\n",
    "    predict = np.array(np.dot(X_test,np.array([reg.coef_]).T) > 0.01) * 1\n",
    "    kfold_predict.append(predict)\n",
    "\n",
    "    n_right = np.sum((np.array(y_test) - np.array(predict[:,0]) == 0))\n",
    "\n",
    "    n_right_planet = np.sum(np.logical_and(np.array(y_test) - np.array(predict[:,0]) == 0, np.array(y_test) == 1))\n",
    "    n_falsepos = np.sum(np.logical_and(np.array(y_test) - np.array(predict[:,0]) != 0 , np.array(y_test) == 0))\n",
    "    n_falseneg = np.sum(np.logical_and(np.array(y_test) - np.array(predict[:,0]) != 0 , np.array(y_test) == 1))\n",
    "    \n",
    "    kfold_classifies.append([n_right,n_right_planet,n_falsepos,n_falseneg])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # xtest.shape = (n_test, 6)\n",
    "    # np.array([reg.coef_]).T.shape = (6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.51582834e-03,  1.26041530e-02, -3.12241372e-02,  1.74170931e-02,\n",
       "        3.44142540e-04, -4.76325891e-05])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(kfold_coefs,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.915     , -0.13922536,  0.18540576, -0.14971114,  0.19961377,\n",
       "       -8.05163011])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116289.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs = \"197 1812 264 2147 1986 6793 15679 11450 12916 19483 13025 11986 4119 757 2439 2891 2790 2873 2682\".split()\n",
    "sum = 0\n",
    "for i in range(len(lcs)):\n",
    "    sum += float(lcs[i])\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.915     , -0.13922536,  0.18540576, -0.14971114,  0.19961377,\n",
       "       -8.05163011])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
